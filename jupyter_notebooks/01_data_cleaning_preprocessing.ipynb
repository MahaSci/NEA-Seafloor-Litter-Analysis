{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning & Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* This notebook comprises the data cleaning and preprocessing steps necessary to ensure the data is in a suitable format for subsequent visualisations and analysis.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write down which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/mahahussain/Desktop/NEA-Seafloor-Litter-Analysis/NEA-Seafloor-Litter-Analysis/jupyter_notebooks'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/mahahussain/Desktop/NEA-Seafloor-Litter-Analysis/NEA-Seafloor-Litter-Analysis'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1: Design & Implement an ETL Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Extract: Importing Libraries & Extracting Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section involves:\n",
        "- Importing the required libraries.\n",
        "- Loading the data from a CSV file into a Pandas DataFrame. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "'''\n",
        "Importing necessary libraries\n",
        "    1) Pandas: for data manipulation and analysis\n",
        "    2) NumPy: for numerical operations\n",
        "'''\n",
        "import pandas as pd \n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset in with read_csv()\n",
        "raw_df = pd.read_csv(\"data/01_RAW_NEA-Seafloor-Litter.csv\")\n",
        "\n",
        "# Verify successful operation\n",
        "print(\"Dataset loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Understanding the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section involves:\n",
        "- Examining column data types and counts\n",
        "- Correcting incorrect types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checking Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ----- Data Types -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4310 entries, 0 to 4309\n",
            "Data columns (total 62 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   year               4310 non-null   int64  \n",
            " 1   survey             4310 non-null   object \n",
            " 2   cruise             4310 non-null   object \n",
            " 3   area               4033 non-null   object \n",
            " 4   station            4310 non-null   int64  \n",
            " 5   fldHaulLatDegrees  4310 non-null   int64  \n",
            " 6   fldHaulLatMinutes  4052 non-null   float64\n",
            " 7   fldHaulLonDegrees  4310 non-null   int64  \n",
            " 8   fldHaulLonMinutes  4052 non-null   float64\n",
            " 9   fldHaulEorW        4057 non-null   object \n",
            " 10  fldShotLatDegrees  3829 non-null   float64\n",
            " 11  fldShotLatMinutes  3603 non-null   float64\n",
            " 12  fldShotLonDegrees  3745 non-null   float64\n",
            " 13  fldShotLonMinutes  3519 non-null   float64\n",
            " 14  fldShotEorW        3519 non-null   object \n",
            " 15  Latitude           4310 non-null   float64\n",
            " 16  Longitude          4310 non-null   float64\n",
            " 17  fldDateTimeShot    4310 non-null   object \n",
            " 18  bottle             4310 non-null   int64  \n",
            " 19  sheet              4310 non-null   int64  \n",
            " 20  bag                4310 non-null   int64  \n",
            " 21  caps               4310 non-null   int64  \n",
            " 22  fishline.mono      4310 non-null   int64  \n",
            " 23  fishline.tang      4310 non-null   int64  \n",
            " 24  synthrope          4310 non-null   int64  \n",
            " 25  fishnet            4310 non-null   int64  \n",
            " 26  cabletie           4310 non-null   int64  \n",
            " 27  strap              4310 non-null   int64  \n",
            " 28  crates             4310 non-null   int64  \n",
            " 29  nappies            4310 non-null   int64  \n",
            " 30  santowels          4310 non-null   int64  \n",
            " 31  other.plas         4310 non-null   int64  \n",
            " 32  cansfood           4310 non-null   int64  \n",
            " 33  cansdrink          4310 non-null   int64  \n",
            " 34  fishmetal          4310 non-null   int64  \n",
            " 35  drums              4310 non-null   int64  \n",
            " 36  appliance          4310 non-null   int64  \n",
            " 37  carparts           4310 non-null   int64  \n",
            " 38  cables             4310 non-null   int64  \n",
            " 39  other.metal        4310 non-null   int64  \n",
            " 40  wellies            4310 non-null   int64  \n",
            " 41  balloon            4310 non-null   int64  \n",
            " 42  bobbins            4310 non-null   int64  \n",
            " 43  tyre               4310 non-null   int64  \n",
            " 44  gloves             4310 non-null   int64  \n",
            " 45  other.rub          4310 non-null   int64  \n",
            " 46  jars               4310 non-null   int64  \n",
            " 47  bottles            4310 non-null   int64  \n",
            " 48  pieces             4310 non-null   int64  \n",
            " 49  other.glass        4310 non-null   int64  \n",
            " 50  woodnat            4310 non-null   int64  \n",
            " 51  woodproc           4310 non-null   int64  \n",
            " 52  rope               4310 non-null   int64  \n",
            " 53  paper              4310 non-null   int64  \n",
            " 54  pallets            4310 non-null   int64  \n",
            " 55  other.wood         4310 non-null   int64  \n",
            " 56  clothing           4310 non-null   int64  \n",
            " 57  shoes              4310 non-null   int64  \n",
            " 58  other.misc         4310 non-null   int64  \n",
            " 59  totallitter        4310 non-null   int64  \n",
            " 60  distance           4310 non-null   int64  \n",
            " 61  wingspread         4310 non-null   int64  \n",
            "dtypes: float64(8), int64(48), object(6)\n",
            "memory usage: 2.0+ MB\n",
            "None\n",
            " ----- First Five Rows -----\n",
            "   year survey     cruise               area  station  fldHaulLatDegrees  \\\n",
            "0  1992   IBTS  CIRO 9/92  Greater North Sea        1                 51   \n",
            "1  1992   IBTS  CIRO 9/92  Greater North Sea        2                 51   \n",
            "2  1992   IBTS  CIRO 9/92  Greater North Sea        3                 51   \n",
            "3  1992   IBTS  CIRO 9/92  Greater North Sea        4                 52   \n",
            "4  1992   IBTS  CIRO 9/92  Greater North Sea        5                 52   \n",
            "\n",
            "   fldHaulLatMinutes  fldHaulLonDegrees  fldHaulLonMinutes fldHaulEorW  ...  \\\n",
            "0               44.3                  1               45.2           E  ...   \n",
            "1               36.1                  2               47.8           E  ...   \n",
            "2               49.4                  3               38.6           E  ...   \n",
            "3               49.4                  2               45.6           E  ...   \n",
            "4               41.1                  3               24.7           E  ...   \n",
            "\n",
            "   rope  paper  pallets  other.wood clothing  shoes  other.misc totallitter  \\\n",
            "0     0      0        0           0        0      0           0           1   \n",
            "1     0      0        0           0        0      0           0           2   \n",
            "2     0      0        0           0        0      0           0           1   \n",
            "3     0      0        0           0        0      0           0           1   \n",
            "4     0      0        0           0        0      0           0           2   \n",
            "\n",
            "   distance  wingspread  \n",
            "0      3794           0  \n",
            "1      3918           0  \n",
            "2      3624           0  \n",
            "3      3642           0  \n",
            "4      3791           0  \n",
            "\n",
            "[5 rows x 62 columns]\n"
          ]
        }
      ],
      "source": [
        "def check_data_and_types(data_frame):\n",
        "    \"\"\"\n",
        "    This function shows the type of data for each column and the first 5 rows of the dataset.\n",
        "\n",
        "    Args: data_frame: The data frame we want to inspect.\n",
        "    \"\"\"\n",
        "    print(\" ----- Data Types -----\")\n",
        "    print(data_frame.info())\n",
        "\n",
        "    print(\" ----- First Five Rows -----\")\n",
        "    print(data_frame.head())\n",
        "\n",
        "check_data_and_types(raw_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using value_counts() to examine frequency of each unique value in select columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Value count for year:\n",
            "year\n",
            "2011    640\n",
            "2010    570\n",
            "2014    503\n",
            "2013    484\n",
            "2012    416\n",
            "2015    277\n",
            "2009    163\n",
            "1994    150\n",
            "1992    149\n",
            "1993    146\n",
            "2008    111\n",
            "2000     92\n",
            "2005     86\n",
            "1999     74\n",
            "1998     74\n",
            "1997     74\n",
            "1995     74\n",
            "1996     72\n",
            "2007     31\n",
            "2003     28\n",
            "2006     27\n",
            "2004     25\n",
            "2001     22\n",
            "2002     22\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Value count for survey:\n",
            "survey\n",
            "IBTS                 1575\n",
            "NWGFS                 566\n",
            "Q1SW_with Blinder     496\n",
            "7DBTS                 444\n",
            "Q1SW_No Blinder       408\n",
            "CSEMP                 368\n",
            "Q4SW                  220\n",
            "Q1SW                  138\n",
            "MEMFISH                95\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Value count for cruise:\n",
            "cruise\n",
            "CEND 4/15     277\n",
            "Cend04/14     192\n",
            "Cend5/11      175\n",
            "Cend6/10      172\n",
            "CEND 02/13    142\n",
            "Cend 18/13    118\n",
            "CEND 13/12    118\n",
            "CEND 15/11    116\n",
            "Cend 18/14    112\n",
            "CEND 14/10    112\n",
            "CEND 15/12    108\n",
            "CEND4/11       95\n",
            "Cend 12/10     94\n",
            "CEND 11/12     93\n",
            "CEND 15/14     91\n",
            "CEND 13/10     90\n",
            "CEND 12/09     90\n",
            "Cend 15/13     89\n",
            "CEND 14/11     88\n",
            "CEND 12/13     85\n",
            "CEND5/12       84\n",
            "CEND 13/11     81\n",
            "Cend 17/14     81\n",
            "CEND 17/10     79\n",
            "CIRO 6/00      75\n",
            "CIRO 11/94     75\n",
            "CIRO 9/94      75\n",
            "CIRO 9/92      75\n",
            "CIRO 7/95      74\n",
            "CIRO 7/97      74\n",
            "CIRO 8/93      74\n",
            "CIRO 6/99      74\n",
            "CIRO 11/92     74\n",
            "CEND 15/08     74\n",
            "CIRO 4/98      74\n",
            "Cend 17/09     73\n",
            "CIRO 10/93     72\n",
            "CIRO 8/96      72\n",
            "CEND 19/11     68\n",
            "CEND 13/05     57\n",
            "Cend11/13      50\n",
            "CSEMP2008      37\n",
            "CSEMP2007      31\n",
            "CSEMP2005      29\n",
            "CSEMP2003      28\n",
            "Cend14/14      27\n",
            "CSEMP2006      27\n",
            "CSEMP2004      25\n",
            "CESEMP2010     23\n",
            "CSEMP2002      22\n",
            "CSEMP2001      22\n",
            "CSEMP2000      17\n",
            "CSEMP2011      17\n",
            "CEND9/12       13\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Value count for area:\n",
            "area\n",
            "Greater North Sea    2241\n",
            "Celtic Seas          1792\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Value count for station:\n",
            "station\n",
            "0      1031\n",
            "7        39\n",
            "22       38\n",
            "47       37\n",
            "53       37\n",
            "       ... \n",
            "290       1\n",
            "142       1\n",
            "292       1\n",
            "108       1\n",
            "287       1\n",
            "Name: count, Length: 320, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def get_value_counts(data_frame):\n",
        "   \"\"\"\n",
        "    This function shows the frequency of each category for the following columns:\n",
        "    1. year\n",
        "    2. survey\n",
        "    3. cruise\n",
        "    4. area\n",
        "    5. station\n",
        "\n",
        "   It provides the count of each unique category for the specified columns.\n",
        "\n",
        "    Args: data_frame: The data frame to inspect.\n",
        "    \"\"\"\n",
        "   \n",
        "   # Create a list of the columns to inspect\n",
        "   columns_to_check = ['year', 'survey', 'cruise', 'area', 'station']\n",
        "\n",
        "   # For every col in the list, print its title and its value counts\n",
        "   for col in columns_to_check:\n",
        "      print(f\"\\n Value count for {col}:\")\n",
        "      print(data_frame[col].value_counts())\n",
        "    \n",
        "get_value_counts(raw_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **AI Insights for Value Counts**\n",
        "   **Year Distribution**\n",
        "  - The data spans several years, with 2011 having the highest count (640) and 2002 the lowest (22).\n",
        "  - The year range covers both recent and older periods, with a noticeable decrease in data points as you go further back in time.\n",
        "  - The years 2011, 2010, and 2014 dominate, indicating that more data was collected in those years.\n",
        "\n",
        "  **Survey Distribution**\n",
        "  - **IBTS** survey has the highest count (1575), significantly outpacing all other surveys.\n",
        "  - The next largest survey is **NWGFS** (566), followed by **Q1SW_with Blinder** (496), suggesting these surveys might be more extensive or more frequently conducted.\n",
        "  - Other surveys, such as **MEMFISH** (95) and **Q1SW** (138), have significantly lower counts, indicating they might be more specialised or less frequent.\n",
        "\n",
        "  **Cruise Distribution**\n",
        "  - **CEND 4/15** has the highest cruise count (277), followed by other CEND series cruises (e.g., **Cend04/14**, **Cend5/11**), which seem to be relatively frequent (counts between 90 and 200).\n",
        "  - Several cruises with **CIRO** prefixes (e.g., **CIRO 6/00**, **CIRO 11/94**) have counts of 75, indicating they were conducted on a few key occasions.\n",
        "  - Some cruises like **CSEMP2008** (37) and **CSEMP2007** (31) show smaller numbers, likely due to being more specific or infrequent surveys.\n",
        "\n",
        "  **Area Distribution**\n",
        "  - Two main areas: **Greater North Sea** (2241) and **Celtic Seas** (1792).\n",
        "  - **Greater North Sea** has a significantly higher count, indicating it may be a more frequently surveyed or larger region compared to the **Celtic Seas**.\n",
        "  \n",
        "  **Station Distribution**\n",
        "  - Station values are widely distributed:\n",
        "    - **Station 0** has the highest count (1031), indicating it's a primary or central location.\n",
        "    - Other stations have significantly lower counts, with some stations (like 290, 142, 292) having only 1 count, suggesting they represent rare or specific locations.\n",
        "\n",
        "\n",
        "#### **Observations**\n",
        "From the analysis, it's clear that the data collection has been much more concentrated in recent years, particularly around 2010-2014. The dominance of the **IBTS** survey suggests it's the primary source of the data, with a smaller set of other surveys contributing. The variety in the number of cruises and the regions surveyed shows that the data may come from both regular, extensive surveys (Greater North Sea) and more targeted studies in specific areas. It also seems that Station 0 is the central location for data collection, while others are used sparingly or for more niche observations. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using nunique() to Check Cardinality (Number of Unique Values of Spec. Column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique years: 24\n",
            "Number of unique surveys: 9\n",
            "Number of unique cruises: 54\n",
            "Number of unique areas: 2\n",
            "Number of unique stations: 320\n"
          ]
        }
      ],
      "source": [
        "def get_cardinality(data_frame):\n",
        "   \"\"\"\n",
        "    This function shows the count of distinct categories for the following columns:\n",
        "    1. year\n",
        "    2. survey\n",
        "    3. cruise\n",
        "    4. area\n",
        "    5. station\n",
        "\n",
        "    Args: data_frame: The data frame to inspect.\n",
        "    \"\"\"\n",
        "       \n",
        "   # Create a list of the columns to inspect\n",
        "   cols = ['year', 'survey', 'cruise', 'area', 'station']\n",
        "\n",
        "   # For every col in the list, print its title and its value counts\n",
        "   for col in cols:\n",
        "      unqiue_count = data_frame[col].nunique()\n",
        "      print(f\"Number of unique {col}s: {unqiue_count}\") \n",
        "  \n",
        "    \n",
        "get_cardinality(raw_df)\n",
        "       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **AI Insights for Unique Category Counts**\n",
        "**Year Distribution**\n",
        "- The data spans across **24 unique years**, indicating a broad temporal range of data collection.\n",
        "- The presence of multiple years reflects long-term monitoring, with a focus on both recent and older data points.\n",
        "\n",
        "**Survey Distribution**\n",
        "- **9 unique surveys** are represented, showcasing a diverse range of research efforts.\n",
        "- The presence of multiple surveys suggests a variety of research methodologies and objectives, capturing different aspects of the dataset.\n",
        "\n",
        "**Cruise Distribution**\n",
        "- The data covers **54 unique cruises**, indicating a diverse set of research trips or expeditions.\n",
        "- The variety in cruises suggests both extensive and more specific sampling events across various periods.\n",
        "\n",
        "**Area Distribution**\n",
        "- The data is focused on **2 unique areas**, likely representing two primary regions of interest.\n",
        "- These areas may have distinct environmental conditions, offering opportunities for comparison and regional analysis.\n",
        "\n",
        "**Station Distribution**\n",
        "- The dataset includes data from **320 unique stations**, reflecting a detailed geographical distribution.\n",
        "- The large number of stations suggests a comprehensive sampling effort, providing rich spatial data for analysis.\n",
        "\n",
        "#### **Observations**\n",
        "- The data spans a significant time period with 24 years of collected data.\n",
        "- The variety in the number of surveys, cruises, and stations shows a comprehensive and diverse data collection effort, capturing both broad trends and specific research events.\n",
        "- The focus on two primary areas highlights regional interest, while the extensive number of stations offers a high level of detail and spatial resolution in the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create your folder here\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
